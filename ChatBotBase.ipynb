{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBotBase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielKorenDataScience/NLP-FinalProject/blob/main/ChatBotBase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pn7vffOmd3B"
      },
      "source": [
        "from importlib import import_module\n",
        "def my_import(lib, package=None, func=None):\n",
        "  try:\n",
        "    import_module(lib)\n",
        "  except:\n",
        "    if package is None: package = lib\n",
        "    !pip install \"{package}\"\n",
        "    import_module(lib)\n",
        "  \n",
        "  if func is not None:\n",
        "    return import_module(lib).__getattribute__(func)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUe0RUXkmd3v",
        "outputId": "376897f9-cd3c-43da-bca5-17f02ca7ef7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_import('pyforest')\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "p = print\n",
        "d = display"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/ae/418f9bbcfb442bb6775f294451c97e134f84c8c4f47d75208419e4af7e13/pyforest-1.1.0.tar.gz\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14606 sha256=fb9f8b6f55ba63c58f24fb3a0373b2099107fcca520e078ff248093057ab2c9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/c6/da/43562aeea85b37f1a2b3d326f0f602f865000d2ada8a43625f\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5Zn-z6md3-",
        "outputId": "c27432a1-9df8-46c3-810b-36f75e0f4dc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_import('spacy')\n",
        "from spacy.tokens import Doc, Span\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Load md (medium) English tokenizer, tagger, parser and NER, and vectors(vectors are not included in the 'sm' model)\n",
        "#nlp = spacy.load('en_core_web_md')  NOT WORKING ON COLAB\n",
        "try:\n",
        "  import en_core_web_md\n",
        "except:  \n",
        "  !python -m spacy download en_core_web_md\n",
        "  import en_core_web_md\n",
        "  \n",
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp37-none-any.whl size=98051304 sha256=ab6fdd9ceab8633253d73ab8826da841ace403e252d921b9864abb3058c8d757\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9hq_bhzu/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdnCbXKo5cwo"
      },
      "source": [
        "import requests\n",
        "\n",
        "api_key = 'c2adfa29edfd95ad16efab9218619ff3'\n",
        "URL = \"http://api.openweathermap.org/data/2.5/weather?\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8DgeWTF03z"
      },
      "source": [
        "path = '/content/drive/MyDrive/Project5_ChatBot/'\n",
        "data_url = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/' "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFqfk8lMh8x-"
      },
      "source": [
        "TEST = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1pXmhO4ugH"
      },
      "source": [
        "# Call the web site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhygq47xtL1r"
      },
      "source": [
        "{\"coord\":{\"lon\":34.8,\"lat\":32.0833},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"base\":\"stations\",\"main\":{\"temp\":295.69,\"feels_like\":295.83,\"temp_min\":294.42,\"temp_max\":296.58,\"pressure\":1016,\"humidity\":70},\"visibility\":10000,\"wind\":{\"speed\":2.06,\"deg\":10},\"clouds\":{\"all\":20},\"dt\":1623961727,\"sys\":{\"type\":1,\"id\":6845,\"country\":\"IL\",\"sunrise\":1623897263,\"sunset\":1623948546},\"timezone\":10800,\"id\":293396,\"name\":\"Tel Aviv\",\"cod\":200}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQObVOJn-LGD"
      },
      "source": [
        "WEATHER_ONLY = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkn5WmrShACd"
      },
      "source": [
        "def call_web(city_name):\n",
        "    api_url = URL + \"q={}&appid={}\".format(city_name, api_key)\n",
        "\n",
        "    response = requests.get(api_url)\n",
        "    response_dict = response.json()\n",
        "\n",
        "    weather = response_dict #[\"weather\"]#[0]#[\"description\"]\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return weather\n",
        "    elif response.status_code == 404:\n",
        "        return None\n",
        "    else:\n",
        "        print('[!] HTTP {0} calling [{1}]'.format(response.status_code, api_url))\n",
        "        return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1XIdfNeh1d5"
      },
      "source": [
        "def get_weather(dt, location, action = None):\n",
        "  template = WEATHER_ONLY\n",
        "\n",
        "  city_w = city = location[0][0]  # assume one city (not handling ifthere are 2 cities)\n",
        "  #p(city, city_w)\n",
        "  result = ''\n",
        "  # check if city in api_city list\n",
        "  if city in df_CITIES_API.index.values:\n",
        "    result = df_CITIES_API.loc[city]\n",
        "  if len(result) == 0: # not found, get district\n",
        "    if city in cities_il_df.index.values:\n",
        "      city_w = cities_il_df.loc[city].district\n",
        "  elif len(result) > 0: # more than one city -> need country\n",
        "    pass\n",
        "\n",
        "  #p(city_w)\n",
        "\n",
        "  city_weather = call_web(city_w)\n",
        "  if city_weather is not None:\n",
        "    if template == WEATHER_ONLY:\n",
        "      result = city_weather[\"weather\"][0][\"description\"]\n",
        "    return f\"In {city.capitalize()}, {location[0][1].capitalize()} the current weather is: {result}\"\n",
        "  else:\n",
        "    return \"Something went wrong.\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMXfN0EnkL3a"
      },
      "source": [
        "# Get cities and update model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF2CJIu3pOik"
      },
      "source": [
        "GIT = True\n",
        "git_path = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/'\n",
        "\n",
        "def get_json(fname, GIT=True):\n",
        "  p(fname)\n",
        "  if GIT:\n",
        "    resp = requests.get(data_url + fname)\n",
        "    return json.loads(resp.text)\n",
        "  with open(path + fname, encoding=\"utf8\") as f:\n",
        "    return json.loads(f.read())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyn9GTNLu_XA",
        "outputId": "6b446401-a886-46ec-deb5-7d4c693c69cd"
      },
      "source": [
        "intents = get_json('intents.json')\n",
        "#intents"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intents.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVyPlh34vAJ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "275d7827-a06d-48e1-b544-3099c59cb7e2"
      },
      "source": [
        "my_import('wget')\n",
        "import wget\n",
        "\n",
        "def load_CITIES_API():\n",
        "  # file too big for git so read it from my google drive using a shared link\n",
        "  #CITIES_API = get_json('city.list.json', GIT=False)\n",
        "\n",
        "  google_shared_link = 'https://drive.google.com/file/d/19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT/view?usp=sharing'\n",
        "  url = 'https://drive.google.com/uc?authuser=0&id=19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT&export=download'\n",
        "  file_id = '19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT'\n",
        "\n",
        "  wget.download(url)  # download the file to local google drive with the original name in the sahre link\n",
        "  # now can open with no path because it is in the local 'colab' directory\n",
        "  with open('city.list.json', encoding=\"utf8\") as f:\n",
        "     CITIES_API = json.loads(f.read())\n",
        "\n",
        "  df = pd.DataFrame(CITIES_API)\n",
        "  df = df.drop(['id', 'coord'], axis='columns')\n",
        "  df.name = df.name.str.lower()\n",
        "  df.name = df.name.str.translate(remove_punct_dict)\n",
        "\n",
        "  CITIES_API_city = sorted(set(df.name.to_list()))\n",
        "  CITIES_API_country = sorted(set(df.country.str.lower().to_list()))\n",
        "  if CITIES_API_country[0] == '':\n",
        "    CITIES_API_country = CITIES_API_country[1:]\n",
        "  CITIES_API_state = sorted(set(df.state.str.lower().to_list()))\n",
        "  if CITIES_API_state[0] == '':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  if CITIES_API_state[0] == '00':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  \n",
        "  df.set_index('name', inplace=True)\n",
        "  #d(df.head)\n",
        "  return df, CITIES_API_city, CITIES_API_country, CITIES_API_state\n",
        "\n",
        "df_CITIES_API, CITIES_API_city, CITIES_API_country_code, CITIES_API_state_code = load_CITIES_API()\n",
        "df_CITIES_API.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=5587168e964b6dad02dfdf6b07c68367c2a752a48d0dae959dfdef629f2f555e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ḩeşāre sefīd</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘ayn ḩalāqīm</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taglag</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qabāghlū</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘arīqah</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             state country\n",
              "name                      \n",
              "ḩeşāre sefīd            IR\n",
              "‘ayn ḩalāqīm            SY\n",
              "taglag                  IR\n",
              "qabāghlū                IR\n",
              "‘arīqah                 SY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u5cXlHgxKsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "52ed53ce-54ff-439c-9939-f7c4aa25ade2"
      },
      "source": [
        "def load_countries():\n",
        "  path_ = path  \n",
        "  fname = 'countries.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname)\n",
        "  df.Name = df.Name.str.lower()\n",
        "  COUNTRIES = df.Name.tolist()\n",
        "  df = df.set_index('Code')\n",
        "  return df, COUNTRIES\n",
        "\n",
        "countries_df, COUNTRIES = load_countries()\n",
        "countries_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AF</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AX</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AL</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DZ</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AS</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name\n",
              "Code                \n",
              "AF       afghanistan\n",
              "AX     åland islands\n",
              "AL           albania\n",
              "DZ           algeria\n",
              "AS    american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "W1gHA85O9isU",
        "outputId": "6e54df50-2b82-4f49-c77a-ac47bb2ca884"
      },
      "source": [
        "def load_cities_il():\n",
        "  path_ = path\n",
        "  fname = 'cities_IL.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, names=['city', 'district'])\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  CITIES = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, CITIES\n",
        "cities_il_df, CITIES_IL = load_cities_il()\n",
        "cities_il_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>asam</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abbirim</th>\n",
              "      <td>acre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu abdun</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu ammar</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu amre</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            district\n",
              "city                \n",
              "asam       beersheba\n",
              "abbirim         acre\n",
              "abu abdun  beersheba\n",
              "abu ammar  beersheba\n",
              "abu amre   beersheba"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "J-gKXG1hHu4J",
        "outputId": "3d18736c-423e-4e52-f7da-35005995add6"
      },
      "source": [
        "def load_capitals():\n",
        "  path_ = path\n",
        "  fname = 'capitals.json'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  CAPITALS = pd.read_json(path_ + fname, encoding=\"utf8\", typ='series').str.lower()\n",
        "\n",
        "  CAPITALS.index = CAPITALS.index.str.lower()\n",
        "  df = pd.DataFrame([CAPITALS])\n",
        "  df = df.T\n",
        "  df = df.reset_index()\n",
        "  df.columns = ['country', 'capital']\n",
        "  df = df.set_index('capital')\n",
        "  return df, CAPITALS.to_dict()\n",
        "capitals_df, CAPITALS = load_capitals()\n",
        "\n",
        "p(CAPITALS['albania'])\n",
        "p(capitals_df.loc['madrid'].country)\n",
        "capitals_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tirana\n",
            "spain\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kabul</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mariehamn</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tirana</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algiers</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pago pago</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  country\n",
              "capital                  \n",
              "kabul         afghanistan\n",
              "mariehamn   åland islands\n",
              "tirana            albania\n",
              "algiers           algeria\n",
              "pago pago  american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "1YMQgZMecwVh",
        "outputId": "c3de9b3c-2497-4bcd-fd21-0a13b6905e7e"
      },
      "source": [
        "def load_largest():\n",
        "  fname = '100-largest-cities.csv'\n",
        "  path_ = path\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, encoding='ISO-8859-8')\n",
        "  df.city = df.city.str.lower()\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  LARGEST = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, LARGEST\n",
        "largest_df, LARGEST = load_largest()\n",
        "\n",
        "d(largest_df.head())\n",
        "p(largest_df.loc['toronto'].country)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tokyo</th>\n",
              "      <td>Japan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delhi</th>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shanghai</th>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so paulo</th>\n",
              "      <td>Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ciudad de mxico mexico city</th>\n",
              "      <td>Mexico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            country\n",
              "city                               \n",
              "tokyo                         Japan\n",
              "delhi                         India\n",
              "shanghai                      China\n",
              "so paulo                     Brazil\n",
              "ciudad de mxico mexico city  Mexico"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Canada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb9JLByJsG9R"
      },
      "source": [
        "#nlp = en_core_web_md.load()\n",
        "def update_nlp():\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  CITIES = set(CITIES_IL + CITIES_API_city)\n",
        "  matcher.add(\"CITIES\", None, *list(nlp.pipe(CITIES)))\n",
        "  # country codes causes problems becuae many are similar to regular words (eg. 'IN' similar to 'in')\n",
        "  #matcher.add(\"CITIES_API_country_code\", None, *list(nlp.pipe(CITIES_API_country_code)))\n",
        "  # due to duplicates with country codes ('IL' = Israel, and Ilinoie), we have to check manually for states\n",
        "  #matcher.add(\"CITIES_API_state_code\", None, *list(nlp.pipe(CITIES_API_state_code)))\n",
        "\n",
        "  # Register the Span extension attributes \"is_country\" and \"is_city\" \n",
        "  check_country = lambda span: span.text.lower().translate(remove_punct_dict) in COUNTRIES\n",
        "  Span.set_extension('is_country', getter=check_country, force=True)\n",
        "\n",
        "  check_city = lambda span: span.text.lower().translate(remove_punct_dict) in CITIES\n",
        "  Span.set_extension('is_city', getter=check_city, force=True)\n",
        "\n",
        "  def gpe_component(doc):\n",
        "      # Create an entity Span with the label \"GPE\" for all matches\n",
        "      matches = matcher(doc)\n",
        "      doc.ents = [Span(doc, start, end, label=\"GPE\") for match_id, start, end in matches]\n",
        "      return doc\n",
        "\n",
        "  # Add the component to the pipeline\n",
        "  pipes = nlp.pipe_names\n",
        "  if 'gpe_component' in pipes:\n",
        "    nlp.remove_pipe('gpe_component')\n",
        "\n",
        "  nlp.add_pipe(gpe_component, first=True)\n",
        "  #print(nlp.pipe_names)\n",
        "\n",
        "update_nlp()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLqojifIudRU"
      },
      "source": [
        "## Get Parts (POS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIUD4FCXyUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153f1de9-cb67-46e2-c55d-1f39d9cb0148"
      },
      "source": [
        "def get_parts(text, disp=False):\n",
        "  global DEBUG\n",
        "  doc = nlp(text.lower().translate(remove_punct_dict))\n",
        "  date, gpe, ents = [], {}, []\n",
        "  action = ''\n",
        "  multiple_cities = False\n",
        "  if disp: p()\n",
        "  for token in doc:\n",
        "    if disp:\n",
        "      p(f'{token.text}, dep_={token.dep_}, ent_type={token.ent_type_}, head={token.head}, lemma_={token.lemma_}, pos_={token.pos_}, tag_={token.tag_}')\n",
        "    if token.ent_type_ == 'GPE': ents.append((token.text.lower(), token))\n",
        "  for entity in doc.ents:\n",
        "      if disp:\n",
        "        print(f\"{entity.text}, {entity.label_}='{spacy.explain(entity.label_)}'\")\n",
        "      ent_text = entity.text.lower().translate(remove_punct_dict)\n",
        "      if entity.label_ == 'DATE': date.append(ent_text)\n",
        "      if entity.label_ == 'GPE':\n",
        "        token = None\n",
        "        for e in ents:\n",
        "          if ent_text == e[0]:\n",
        "            token = e[1] \n",
        "            break\n",
        "        # verify the GPE is a true GPE for cases that a city has a name that has another meaninig\n",
        "        if token and token.text != token.lemma_: # a true GPE cannot be lemmatized\n",
        "          continue\n",
        "        # for example there is a city in Denemark that has a name 'rain'\n",
        "        if token and len(ents) > 1 and (token.head == token or token.pos_ not in ['PROPN', 'PRON', 'NOUN']) and not entity._.is_country:\n",
        "          valid_gpe = False\n",
        "          for e in ents:\n",
        "            if ent_text != e[0]:\n",
        "              tk = e[1]\n",
        "              if tk.head == token:  # the token is connected to another gpe, so it is a valid gpe (for example, (paris, canada) are connected\n",
        "                valid_gpe = True\n",
        "                break\n",
        "          if not valid_gpe:\n",
        "            if DEBUG: p('A:', ent_text)\n",
        "            continue\n",
        "        ent_type = 'state'\n",
        "        if DEBUG: p('0:', ent_text, entity._.is_city, entity._.is_country)\n",
        "        if entity._.is_city and not entity._.is_country: # 'canada' is a country and also a city in Portugal\n",
        "          ent_type = 'city'\n",
        "          if ent_text in df_CITIES_API.index.values: \n",
        "            code_country = df_CITIES_API.loc[ent_text].country\n",
        "            if type(code_country) != str:\n",
        "              multiple_cities = True\n",
        "              ent_country = countries_df.loc[code_country[0]].Name\n",
        "            else:\n",
        "              ent_country = countries_df.loc[code_country].Name\n",
        "          elif ent_text in CITIES_IL:\n",
        "            ent_country = 'israel'\n",
        "          else:\n",
        "            ent_country = ''\n",
        "        elif entity._.is_country or ent_text in CITIES_API_country_code:\n",
        "          ent_type = 'country'\n",
        "\n",
        "        if ent_type not in gpe:\n",
        "          gpe[ent_type] = []\n",
        "        if ent_type == 'city':\n",
        "           gpe[ent_type].append((entity.text, ent_country))\n",
        "        else:\n",
        "          gpe[ent_type].append(entity.text)\n",
        "  if len(date) == 0:\n",
        "    date = 'current'\n",
        "\n",
        "  if DEBUG: p('1:', multiple_cities, gpe)\n",
        "  if multiple_cities:\n",
        "    if 'country' in gpe:\n",
        "      # verify country code of the city is correct, when there multiple cities\n",
        "      for i, (city, city_country) in enumerate(gpe['city']):\n",
        "        country = gpe['country'][0]\n",
        "        if city_country != country:\n",
        "          for code_country in df_CITIES_API.loc[city].country:\n",
        "            if city_country == countries_df.loc[code_country].Name:\n",
        "              # found a matching country\n",
        "              gpe['city'][i] = (city, country)\n",
        "              break\n",
        "    else: # check if one of the cities is a capital or a large city, then use it\n",
        "      for i, (city, city_country) in enumerate(gpe['city']):\n",
        "        if city in capitals_df.index.values:\n",
        "          # found a matching country\n",
        "          city_country = capitals_df.loc[city].country\n",
        "          gpe['city'][i] = (city, city_country)\n",
        "          break\n",
        "        if city in largest_df.index.values:\n",
        "          # found a matching country\n",
        "          city_country = largest_df.loc[city].country\n",
        "          gpe['city'][i] = (city, city_country)\n",
        "          break\n",
        "\n",
        "  elif 'country' in gpe and 'city' not in gpe:  # country without city, get the capital\n",
        "    country = gpe['country'][0]\n",
        "    if country in CAPITALS:\n",
        "      gpe['city'] = [(CAPITALS[country], country)]\n",
        "  result = {}\n",
        "  result['date'] = date\n",
        "  result.update(gpe)\n",
        "  if disp:\n",
        "    p(result)\n",
        "  elif 'city' not in result:\n",
        "    p(f'org [{text}], {result}')\n",
        "  return result\n",
        "\n",
        "DEBUG = False\n",
        "if TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"Today weather in a Ra'anana\")  \n",
        "  get_parts(\"Today weather in a Raanana\")\n",
        "  get_parts(\"weather in toronto\")\n",
        "  get_parts(\"weather in toronto, canada\")\n",
        "  get_parts(\"weather paris next 5 days\")\n",
        "  get_parts(\"tell me how is the weather in the ra- anana in the\")\n",
        "  get_parts(\"rain in toronto\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "org [tell me how is the weather in the ra- anana in the], {'date': 'current'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwaYy7z-8vfo",
        "outputId": "0ee40710-dba6-4088-8e09-ea76ae220f39"
      },
      "source": [
        "get_parts(\"please tell me if it will rain tonight in Rain\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "org [please tell me if it will rain tonight in Rain], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQv631Mpz7Xw",
        "outputId": "d3d8686c-4959-4f29-cf19-3d14414e8c3b"
      },
      "source": [
        "DEBUG = False\n",
        "get_parts(\"tomorrow and today rain in spain\")\n",
        "get_parts(\"tomorrow rain in madrid\")\n",
        "get_parts(\"tomorrow rain in beersheba\")\n",
        "get_parts(\"tomorrow rain in israel\")\n",
        "get_parts(\"weather paris Canada\")\n",
        "get_parts(\"weather paris, Canada\")\n",
        "get_parts(\"tomorrow rain in yafo\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('yafo', 'israel')], 'date': ['tomorrow']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcfVvMeRddoX"
      },
      "source": [
        "if TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"weather in tel aviv\")\n",
        "  get_parts(\"tomorrow weather in haifa\")\n",
        "  get_parts(\"tomorrow rain in beersheba\")\n",
        "  get_parts(\"weather paris today and tomorrow\")\n",
        "  get_parts(\"weather paris\")\n",
        "  get_parts(\"weather paris in December\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SvF3JCO9Qpw"
      },
      "source": [
        "def chatbot_response(text):\n",
        "  return \"\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob4yr4F2eu5e",
        "outputId": "4b306b98-5449-4f43-fd09-057c067c22f3"
      },
      "source": [
        "get_parts(\"ra'anana\")\n",
        "get_parts(\"Today weather in a Tel Aviv\")\n",
        "get_parts(\"weather paris\")\n",
        "get_parts(\"paris weather \")\n",
        "get_parts('Paris weather in')\n",
        "get_parts(\"weather shelomi\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('shelomi', 'israel')], 'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtB-Itaok9Br"
      },
      "source": [
        "## Run the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "4OiSqiCC9wy7",
        "outputId": "6ce842fa-0bf8-48f6-ad48-38758a2a78f1"
      },
      "source": [
        "nltk.download(['punkt', 'stopwords'])\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAr4WaLVDL2x",
        "outputId": "890e64bf-979a-449b-9904-030a8a7de6c6"
      },
      "source": [
        "get_parts(\"weather in tel-aviv\")\n",
        "get_parts(\"weather in TelAviv\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "org [weather in tel-aviv], {'date': 'current'}\n",
            "org [weather in TelAviv], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2lBe7UTUhfO"
      },
      "source": [
        "> when similarity was .075 it matched the sentence\n",
        "\n",
        ">\"tell me how is the weather in the ra- anana in the\"\n",
        "\n",
        ">to \"what's up\" of tag [\"greeting\"] so we increased it to 0.85"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry23BUN9weHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff618793-1050-4da1-f938-62c26c1b2e2b"
      },
      "source": [
        "do = True\n",
        "GREETING, NOANSWER = 0, 3\n",
        "p(intents['intents'][GREETING]['responses'][0])\n",
        "min_similarity = 0.85\n",
        "while do:\n",
        "  user_msg = input().lower().strip()\n",
        "  if user_msg == '':\n",
        "    answers = intents['intents'][NOANSWER]['responses']\n",
        "    p(\"WeatherBot: \" + random.choice(answers))\n",
        "    continue\n",
        "  round = 0\n",
        "  answer = ''\n",
        "  org_msg = user_msg\n",
        "  while round < 2 and do:\n",
        "    doc1 = nlp(user_msg)\n",
        "    answers, tag = None, None\n",
        "    top_similarity = 0\n",
        "    for ints in intents['intents']:\n",
        "      #p(ints)\n",
        "      for text in ints['patterns']:\n",
        "        doc2 = nlp(text)\n",
        "        # Get the similarity of doc1 and doc2\n",
        "        similarity = doc1.similarity(doc2)\n",
        "        #p(f\"{similarity}, {doc2}, {[ints['tag']]}\")\n",
        "        if similarity > top_similarity:\n",
        "          top_similarity = similarity\n",
        "          answers = ints['responses']\n",
        "          tag = ints['tag']\n",
        "  #  p(top_similarity, tag)\n",
        "  #  p(answers)\n",
        "    if top_similarity > min_similarity:\n",
        "      if tag == \"goodbye\":\n",
        "        do = False\n",
        "      if tag in [\"goodbye\", \"greeting\", \"thanks\", \"options\"]:\n",
        "        answer = random.choice(answers)\n",
        "        break\n",
        "    parts = get_parts(user_msg, False)\n",
        "    p(parts)\n",
        "    if 'date' in parts and 'city' in parts:\n",
        "      #p(parts['city'][0][0])\n",
        "      answer = get_weather(parts['date'], parts['city'], action=None)\n",
        "    elif round == 0:\n",
        "      round = 1\n",
        "      user_msg = ''\n",
        "      for token in doc1:\n",
        "        if token.text in stopwords: continue\n",
        "        if token.text[-1] == '-': # take care of 'ra- anana'\n",
        "          user_msg += space + token.text[:-1]\n",
        "          space = ''\n",
        "        else:\n",
        "          user_msg += space + token.text\n",
        "          space = ' '\n",
        "      p(user_msg)\n",
        "      continue\n",
        "    elif round == 1:\n",
        "      round = 2\n",
        "      p(user_msg)\n",
        "      p(org_msg)\n",
        "      continue\n",
        "    break\n",
        "  if answer == '': answer = \"You need to tell me a city to check.\"\n",
        "  p(f\"WeatherBot: {answer}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi. My name is WeatherBot and I'm a chatbot. If you want to exit, type 'Bye' If you want help type 'Help'\n",
            "weather toronto\n",
            "{'date': 'current', 'city': [('toronto', 'Canada')]}\n",
            "WeatherBot: In Toronto, Canada the current weather is: clear sky\n",
            "bye\n",
            "WeatherBot: Bye! Come back again soon.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}