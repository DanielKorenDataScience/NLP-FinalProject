{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBotBase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielKorenDataScience/NLP-FinalProject/blob/main/ChatBotBase_Daniel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pn7vffOmd3B"
      },
      "source": [
        "from importlib import import_module\n",
        "def my_import(lib, package=None, func=None):\n",
        "  try:\n",
        "    import_module(lib)\n",
        "  except:\n",
        "    if package is None: package = lib\n",
        "    if lib == 'spacy':\n",
        "      !pip install \"{package}==2.2.4\"\n",
        "    else:\n",
        "      !pip install \"{package}\"\n",
        "    import_module(lib)\n",
        "  \n",
        "  if func is not None:\n",
        "    return import_module(lib).__getattribute__(func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUe0RUXkmd3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706e897e-6f20-43e1-abee-4b1c600f962a"
      },
      "source": [
        "my_import('pyforest')\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "p = print\n",
        "d = display"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/ae/418f9bbcfb442bb6775f294451c97e134f84c8c4f47d75208419e4af7e13/pyforest-1.1.0.tar.gz\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14606 sha256=e4bc3ea8a0419542d79e091de30e57799bc188f2a57bd7f0d6f25908e9824848\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/c6/da/43562aeea85b37f1a2b3d326f0f602f865000d2ada8a43625f\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5Zn-z6md3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb96de57-505d-493b-cc72-f69c38437382"
      },
      "source": [
        "my_import('spacy')\n",
        "from spacy.tokens import Doc, Span\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Load md (medium) English tokenizer, tagger, parser and NER, and vectors(vectors are not included in the 'sm' model)\n",
        "#nlp = spacy.load('en_core_web_md')  NOT WORKING ON COLAB\n",
        "try:\n",
        "  import en_core_web_md\n",
        "except:  \n",
        "  !python -m spacy download en_core_web_md\n",
        "  import en_core_web_md\n",
        "  \n",
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp37-none-any.whl size=98051304 sha256=57afc96f8343ec53038ef7c2b2e78766e4312bb71e331419b525b7d75e689e80\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f6f5xb3k/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdnCbXKo5cwo"
      },
      "source": [
        "import requests\n",
        "\n",
        "api_key = 'c2adfa29edfd95ad16efab9218619ff3'\n",
        "URL = \"http://api.openweathermap.org/data/2.5/weather?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8DgeWTF03z"
      },
      "source": [
        "path = '/content/drive/MyDrive/Project5_ChatBot/'\n",
        "data_url = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFqfk8lMh8x-"
      },
      "source": [
        "TEST = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1pXmhO4ugH"
      },
      "source": [
        "# Call the web site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhygq47xtL1r"
      },
      "source": [
        "{\"coord\":{\"lon\":34.8,\"lat\":32.0833},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"base\":\"stations\",\"main\":{\"temp\":295.69,\"feels_like\":295.83,\"temp_min\":294.42,\"temp_max\":296.58,\"pressure\":1016,\"humidity\":70},\"visibility\":10000,\"wind\":{\"speed\":2.06,\"deg\":10},\"clouds\":{\"all\":20},\"dt\":1623961727,\"sys\":{\"type\":1,\"id\":6845,\"country\":\"IL\",\"sunrise\":1623897263,\"sunset\":1623948546},\"timezone\":10800,\"id\":293396,\"name\":\"Tel Aviv\",\"cod\":200}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQObVOJn-LGD"
      },
      "source": [
        "WEATHER_ONLY = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkn5WmrShACd"
      },
      "source": [
        "def call_web(city_name, country, count=1):\n",
        "    state = ''\n",
        "    api_url = f\"{URL}q={city_name},{state},{country}&cnt={count}&appid={api_key}\"\n",
        "    #p(api_url)\n",
        "\n",
        "    response = requests.get(api_url)\n",
        "    response_dict = response.json()\n",
        "\n",
        "    weather = response_dict #[\"weather\"]#[0]#[\"description\"]\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return weather\n",
        "    elif response.status_code == 404:\n",
        "        return None\n",
        "    else:\n",
        "        print('[!] HTTP {0} calling [{1}]'.format(response.status_code, api_url))\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1XIdfNeh1d5"
      },
      "source": [
        "def get_weather(dt, location, action = None):\n",
        "  template = WEATHER_ONLY\n",
        "\n",
        "  city_w = city = location[0][0]  # assume one city (not handling ifthere are 2 cities)\n",
        "  #p(city, city_w)\n",
        "  result = ''\n",
        "  # check if city in api_city list\n",
        "  if city in df_CITIES_API.index.values:\n",
        "    result = df_CITIES_API.loc[city]\n",
        "  if len(result) == 0: # not found, get district\n",
        "    if city in cities_il_df.index.values:\n",
        "      city_w = cities_il_df.loc[city].district\n",
        "  elif len(result) > 0: # more than one city -> need country\n",
        "    pass\n",
        "\n",
        "  #p(city_w)\n",
        "  country = location[0][1]\n",
        "  country_code = countries_df[countries_df.Name == country].index[0]\n",
        "  \n",
        "  city_weather = call_web(city_w, country_code)\n",
        "  if city_weather is not None:\n",
        "    if template == WEATHER_ONLY:\n",
        "      result = city_weather[\"weather\"][0][\"description\"]\n",
        "    return f\"In {city.capitalize()}, {location[0][1].capitalize()} the current weather is: {result}\"\n",
        "  else:\n",
        "    return \"Something went wrong.\"\n",
        " \n",
        "#answer = get_weather('current', [('toronto', 'united states')])\n",
        "#answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMXfN0EnkL3a"
      },
      "source": [
        "# Get cities and update model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF2CJIu3pOik"
      },
      "source": [
        "GIT = True\n",
        "git_path = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/'\n",
        "\n",
        "def get_json(fname, GIT=True):\n",
        "  p(fname)\n",
        "  if GIT:\n",
        "    resp = requests.get(data_url + fname)\n",
        "    return json.loads(resp.text)\n",
        "  with open(path + fname, encoding=\"utf8\") as f:\n",
        "    return json.loads(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyn9GTNLu_XA",
        "outputId": "47da3bd7-79bf-4cf0-c902-da8dc0222233"
      },
      "source": [
        "intents = get_json('intents.json')\n",
        "#intents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intents.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVyPlh34vAJ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "48161491-23b8-4602-bed1-4846175d280b"
      },
      "source": [
        "def load_CITIES_API():\n",
        "  # file too big for git so read it from my google drive using a shared link\n",
        "  CITIES_API = get_json('city.list.json')\n",
        "  ''' \n",
        "  git_path = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/' + 'city.list.json'\n",
        "  resp = requests.get(git_path)\n",
        "  CITIES_API = json.loads(resp.text)\n",
        "\n",
        "  google_shared_link = 'https://drive.google.com/file/d/19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT/view?usp=sharing'\n",
        "  url = 'https://drive.google.com/uc?authuser=0&id=19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT&export=download'\n",
        "  file_id = '19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT'\n",
        "  \n",
        "  while True:\n",
        "    try:\n",
        "      with open('city.list.json', encoding=\"utf8\") as f:\n",
        "        CITIES_API = json.loads(f.read())\n",
        "      break\n",
        "    except:\n",
        "      wget.download(url)  # download the file to local google drive with the original name in the share link\n",
        "      # now can open with no path because it is in the local 'colab' directory\n",
        "  \n",
        "  '''\n",
        "  df = pd.DataFrame(CITIES_API)\n",
        "  df = df.drop(['id', 'coord'], axis='columns')\n",
        "  df.name = df.name.str.lower()\n",
        "  df.name = df.name.str.translate(remove_punct_dict)\n",
        "\n",
        "  CITIES_API_city = sorted(set(df.name.to_list()))\n",
        "  CITIES_API_country = sorted(set(df.country.str.lower().to_list()))\n",
        "  if CITIES_API_country[0] == '':\n",
        "    CITIES_API_country = CITIES_API_country[1:]\n",
        "  CITIES_API_state = sorted(set(df.state.str.lower().to_list()))\n",
        "  if CITIES_API_state[0] == '':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  if CITIES_API_state[0] == '00':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  \n",
        "  df.set_index('name', inplace=True)\n",
        "  #d(df.head)\n",
        "  return df, CITIES_API_city, CITIES_API_country, CITIES_API_state\n",
        "\n",
        "df_CITIES_API, CITIES_API_city, CITIES_API_country_code, CITIES_API_state_code = load_CITIES_API()\n",
        "df_CITIES_API.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "city.list.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ḩeşāre sefīd</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘ayn ḩalāqīm</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taglag</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qabāghlū</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘arīqah</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             state country\n",
              "name                      \n",
              "ḩeşāre sefīd            IR\n",
              "‘ayn ḩalāqīm            SY\n",
              "taglag                  IR\n",
              "qabāghlū                IR\n",
              "‘arīqah                 SY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u5cXlHgxKsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6f7cd5dc-34b8-453c-afd2-98e64a654539"
      },
      "source": [
        "def load_countries():\n",
        "  path_ = path  \n",
        "  fname = 'countries.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname)\n",
        "  df.Name = df.Name.str.lower()\n",
        "  COUNTRIES = df.Name.tolist()\n",
        "  df = df.set_index('Code')\n",
        "  return df, COUNTRIES\n",
        "\n",
        "countries_df, COUNTRIES = load_countries()\n",
        "countries_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AF</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AX</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AL</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DZ</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AS</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name\n",
              "Code                \n",
              "AF       afghanistan\n",
              "AX     åland islands\n",
              "AL           albania\n",
              "DZ           algeria\n",
              "AS    american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "W1gHA85O9isU",
        "outputId": "dd88f5d6-bc9a-43fd-c799-6adeaac7facd"
      },
      "source": [
        "def load_cities_il():\n",
        "  path_ = path\n",
        "  fname = 'cities_IL.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, names=['city', 'district'])\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  CITIES = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, CITIES\n",
        "cities_il_df, CITIES_IL = load_cities_il()\n",
        "cities_il_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>asam</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abbirim</th>\n",
              "      <td>acre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu abdun</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu ammar</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu amre</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            district\n",
              "city                \n",
              "asam       beersheba\n",
              "abbirim         acre\n",
              "abu abdun  beersheba\n",
              "abu ammar  beersheba\n",
              "abu amre   beersheba"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "J-gKXG1hHu4J",
        "outputId": "4daf16cb-8a78-4082-eeeb-033c5ed17100"
      },
      "source": [
        "def load_capitals():\n",
        "  path_ = path\n",
        "  fname = 'capitals.json'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  CAPITALS = pd.read_json(path_ + fname, encoding=\"utf8\", typ='series').str.lower()\n",
        "\n",
        "  CAPITALS.index = CAPITALS.index.str.lower()\n",
        "  df = pd.DataFrame([CAPITALS])\n",
        "  df = df.T\n",
        "  df = df.reset_index()\n",
        "  df.columns = ['country', 'capital']\n",
        "  df = df.set_index('capital')\n",
        "  return df, CAPITALS.to_dict()\n",
        "capitals_df, CAPITALS = load_capitals()\n",
        "\n",
        "p(CAPITALS['albania'])\n",
        "p(capitals_df.loc['madrid'].country)\n",
        "capitals_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tirana\n",
            "spain\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kabul</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mariehamn</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tirana</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algiers</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pago pago</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  country\n",
              "capital                  \n",
              "kabul         afghanistan\n",
              "mariehamn   åland islands\n",
              "tirana            albania\n",
              "algiers           algeria\n",
              "pago pago  american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "1YMQgZMecwVh",
        "outputId": "ae12426e-7a0f-42b2-8285-e5591f38689c"
      },
      "source": [
        "def load_largest():\n",
        "  fname = '100-largest-cities.csv'\n",
        "  path_ = path\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, encoding='ISO-8859-8')\n",
        "  df.city = df.city.str.lower()\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  LARGEST = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, LARGEST\n",
        "largest_df, LARGEST = load_largest()\n",
        "\n",
        "d(largest_df.head())\n",
        "p(largest_df.loc['toronto'].country)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tokyo</th>\n",
              "      <td>Japan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delhi</th>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shanghai</th>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so paulo</th>\n",
              "      <td>Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ciudad de mxico mexico city</th>\n",
              "      <td>Mexico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            country\n",
              "city                               \n",
              "tokyo                         Japan\n",
              "delhi                         India\n",
              "shanghai                      China\n",
              "so paulo                     Brazil\n",
              "ciudad de mxico mexico city  Mexico"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Canada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb9JLByJsG9R"
      },
      "source": [
        "#nlp = en_core_web_md.load()\n",
        "def update_nlp():\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  CITIES = set(CITIES_IL + CITIES_API_city)\n",
        "\n",
        "  # disable other pipes while doing the traing to speed it up - went down from 1:40 to 0:40 minutes\n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    matcher.add(\"CITIES\", None, *list(nlp.pipe(CITIES)))\n",
        "\n",
        "  # country codes causes problems because many are similar to regular words (eg. 'IN' similar to 'in')\n",
        "  #matcher.add(\"CITIES_API_country_code\", None, *list(nlp.pipe(CITIES_API_country_code)))\n",
        "  # due to duplicates with country codes ('IL' = Israel, and Ilinoie), we have to check manually for states\n",
        "  #matcher.add(\"CITIES_API_state_code\", None, *list(nlp.pipe(CITIES_API_state_code)))\n",
        "\n",
        "  # Register the Span extension attributes \"is_country\" and \"is_city\" \n",
        "  check_country = lambda span: span.text.lower().translate(remove_punct_dict) in COUNTRIES\n",
        "  Span.set_extension('is_country', getter=check_country, force=True)\n",
        "\n",
        "  check_city = lambda span: span.text.lower().translate(remove_punct_dict) in CITIES\n",
        "  Span.set_extension('is_city', getter=check_city, force=True)\n",
        "\n",
        "  def gpe_component(doc):\n",
        "      # Create an entity Span with the label \"GPE\" for all matches\n",
        "      matches = matcher(doc)\n",
        "      doc.ents = [Span(doc, start, end, label=\"GPE\") for match_id, start, end in matches]\n",
        "      return doc\n",
        "\n",
        "  # Add the component to the pipeline\n",
        "  pipes = nlp.pipe_names\n",
        "  if 'gpe_component' in pipes:\n",
        "    nlp.remove_pipe('gpe_component')\n",
        "\n",
        "  nlp.add_pipe(gpe_component, first=True)\n",
        "  #print(nlp.pipe_names)\n",
        "\n",
        "update_nlp()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLqojifIudRU"
      },
      "source": [
        "## Get Parts (POS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIUD4FCXyUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3c0cbe-48bb-4369-cafc-0d64f83fae1c"
      },
      "source": [
        "def get_parts(text, disp=False, verbose=True):\n",
        "  global DEBUG\n",
        "  doc = nlp(text.lower().translate(remove_punct_dict))\n",
        "  date, gpe, ents = [], {}, []\n",
        "  action = ''\n",
        "  multiple_cities = False\n",
        "  if disp: p()\n",
        "  for token in doc:\n",
        "    if disp:\n",
        "      p(f'{token.text}, dep_={token.dep_}, ent_type={token.ent_type_}, head={token.head}, lemma_={token.lemma_}, pos_={token.pos_}, tag_={token.tag_}')\n",
        "    if token.ent_type_ == 'GPE': ents.append((token.text.lower(), token))\n",
        "  for entity in doc.ents:\n",
        "      if disp:\n",
        "        print(f\"{entity.text}, {entity.label_}='{spacy.explain(entity.label_)}', is_city={entity._.is_city}, is_country={entity._.is_country}\")\n",
        "      ent_text = entity.text.lower().translate(remove_punct_dict)\n",
        "      if entity.label_ == 'DATE': date.append(ent_text)\n",
        "      if entity.label_ == 'GPE':\n",
        "        token = None\n",
        "        for e in ents:\n",
        "          if ent_text == e[0]:\n",
        "            token = e[1] \n",
        "            break\n",
        "        # verify the GPE is a true GPE for cases that a city has a name that has another meaninig\n",
        "        if token and token.text != token.lemma_: # a true GPE cannot be lemmatized\n",
        "          continue\n",
        "        # for example there is a city in Denemark that has a name 'rain'\n",
        "        if token and len(ents) > 1 and (token.head == token or token.pos_ not in ['PROPN', 'PRON', 'NOUN']) and not entity._.is_country:\n",
        "          valid_gpe = False\n",
        "          for e in ents:\n",
        "            if ent_text != e[0]:\n",
        "              tk = e[1]\n",
        "              if tk.head == token:  # the token is connected to another gpe, so it is a valid gpe (for example, (paris, canada) are connected\n",
        "                valid_gpe = True\n",
        "                break\n",
        "          if not valid_gpe:\n",
        "            if DEBUG: p('A:', ent_text)\n",
        "            continue\n",
        "        ent_type = 'state'\n",
        "        if DEBUG: p('0:', ent_text, entity._.is_city, entity._.is_country)\n",
        "        if entity._.is_city and not entity._.is_country: # 'canada' is a country and also a city in Portugal\n",
        "          ent_type = 'city'\n",
        "          if ent_text in df_CITIES_API.index.values: \n",
        "            code_country = df_CITIES_API.loc[ent_text].country\n",
        "            if type(code_country) != str:\n",
        "              multiple_cities = True\n",
        "              ent_country = countries_df.loc[code_country.iloc[0]].Name\n",
        "            else:\n",
        "              ent_country = countries_df.loc[code_country].Name\n",
        "          elif ent_text in CITIES_IL:\n",
        "            ent_country = 'israel'\n",
        "          else:\n",
        "            ent_country = ''\n",
        "        elif entity._.is_country or ent_text in CITIES_API_country_code:\n",
        "          ent_type = 'country'\n",
        "\n",
        "        if ent_type not in gpe:\n",
        "          gpe[ent_type] = []\n",
        "        if ent_type == 'city':\n",
        "           gpe[ent_type].append((entity.text, ent_country))\n",
        "        else:\n",
        "          gpe[ent_type].append(entity.text)\n",
        "  if len(date) == 0:\n",
        "    date = 'current'\n",
        "\n",
        "  if DEBUG: p('1:', multiple_cities, gpe)\n",
        "  if multiple_cities or ('city' in gpe and len(gpe['city']) > 1):\n",
        "    if 'country' in gpe:\n",
        "      # verify country code of the city is correct, when there multiple cities\n",
        "      for i, (city, city_country) in enumerate(gpe['city']):\n",
        "        country = gpe['country'][0]\n",
        "        if city_country != country:\n",
        "          for code_country in df_CITIES_API.loc[city].country:\n",
        "            if city_country == countries_df.loc[code_country].Name:\n",
        "              # found a matching country\n",
        "              gpe['city'][i] = (city, country)\n",
        "              break\n",
        "    else:\n",
        "      check_capital = True\n",
        "      if len(gpe['city']) == 2: # maybe enter a country which has city with that name (eg. Toronto, US = there is a city name 'us' in france and 'usa' in japan)\n",
        "        # 'city': [('toronto', 'Canada'), ('us', 'france')]\n",
        "        for i in range(1,-1,-1):\n",
        "          city = gpe['city'][i][0].upper()\n",
        "          if city in countries_df.index: #usually the 2nd \"city\" is the country\n",
        "            city_country = countries_df.loc[city].Name\n",
        "            j = 0 if i == 1 else 1\n",
        "            gpe['city'] = (gpe['city'][j][0], city_country)\n",
        "            gpe['country'] = city_country\n",
        "            check_capital = False\n",
        "            break\n",
        "      if check_capital:\n",
        "        # check if one of the cities is a capital or a large city, then use it\n",
        "        for i, (city, city_country) in enumerate(gpe['city']):\n",
        "          if city in capitals_df.index.values:\n",
        "            # found a matching country\n",
        "            city_country = capitals_df.loc[city].country\n",
        "            gpe['city'][i] = (city, city_country)\n",
        "            break\n",
        "          if city in largest_df.index.values:\n",
        "            # found a matching country\n",
        "            city_country = largest_df.loc[city].country\n",
        "            gpe['city'][i] = (city, city_country)\n",
        "            break\n",
        "  elif 'country' in gpe and 'city' in gpe:  # country with city, verify correct\n",
        "      # verify country code of the city is correct, when user entered \n",
        "      city, city_country = gpe['city'][0]\n",
        "      country = gpe['country'][0]\n",
        "      if city_country != country:\n",
        "        gpe['city'] = [(city, f'ERROR: city [{city}] not found in country [{country}] - try a different spelling of the city')]\n",
        "  elif 'country' in gpe and 'city' not in gpe:  # country without city, get the capital\n",
        "    country = gpe['country'][0]\n",
        "    if country in CAPITALS:\n",
        "      gpe['city'] = [(CAPITALS[country], country)]\n",
        "  result = {}\n",
        "  result['date'] = date\n",
        "  result.update(gpe)\n",
        "  if disp:\n",
        "    p(result)\n",
        "  elif verbose and 'city' not in result:\n",
        "    p(f'FAILED: org [{text}], {result}')\n",
        "  return result\n",
        "\n",
        "DEBUG = False\n",
        "if False and TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"Today weather in a Ra'anana\")  \n",
        "  get_parts(\"Today weather in a Raanana\")\n",
        "  get_parts(\"weather in toronto\") # there is a city toronto in USA and toronto is not the capital of Canada so we take the first city in the db\n",
        "  get_parts(\"weather in toronto, canada\")\n",
        "  get_parts(\"weather paris next 5 days\")\n",
        "  get_parts(\"tell me how is the weather in the ra- anana in the\")\n",
        "  get_parts(\"rain in toronto\")\n",
        "get_parts(\"weather in toronto, us\")\n",
        "get_parts(\"weather in toronto, canada\")\n",
        "get_parts(\"weather in jenin\")\n",
        "get_parts(\"weather in jenin, israel\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('jenin',\n",
              "   'ERROR: city [jenin] not found in country [israel] - try a different spelling of the city')],\n",
              " 'country': ['israel'],\n",
              " 'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwaYy7z-8vfo",
        "outputId": "abb311ed-e6ee-4d86-b0d0-a4468b55a132"
      },
      "source": [
        "get_parts(\"please tell me if it will rain tonight in Rain\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FAILED: org [please tell me if it will rain tonight in Rain], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQv631Mpz7Xw",
        "outputId": "abe017a2-2ad8-42d1-f7ea-f0624c8dab08"
      },
      "source": [
        "DEBUG = False\n",
        "get_parts(\"tomorrow and today rain in spain\")\n",
        "get_parts(\"tomorrow rain in madrid\")\n",
        "get_parts(\"tomorrow rain in beersheba\")\n",
        "get_parts(\"tomorrow rain in israel\")\n",
        "get_parts(\"weather paris Canada\")\n",
        "get_parts(\"weather paris, Canada\")\n",
        "get_parts(\"tomorrow rain in yafo\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('yafo', 'israel')], 'date': ['tomorrow']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcfVvMeRddoX"
      },
      "source": [
        "if TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"weather in tel aviv\")\n",
        "  get_parts(\"tomorrow weather in haifa\")\n",
        "  get_parts(\"tomorrow rain in beersheba\")\n",
        "  get_parts(\"weather paris today and tomorrow\")\n",
        "  get_parts(\"weather paris\")\n",
        "  get_parts(\"weather paris in December\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SvF3JCO9Qpw"
      },
      "source": [
        "def chatbot_response(text):\n",
        "  return \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob4yr4F2eu5e",
        "outputId": "d37f423f-59dd-441b-f93a-b59d447f050b"
      },
      "source": [
        "get_parts(\"ra'anana\")\n",
        "get_parts(\"Today weather in a Tel Aviv\")\n",
        "get_parts(\"weather paris\")\n",
        "get_parts(\"paris weather \")\n",
        "get_parts('Paris weather in')\n",
        "get_parts(\"weather shelomi\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('shelomi', 'israel')], 'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtB-Itaok9Br"
      },
      "source": [
        "## Run the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "4OiSqiCC9wy7",
        "outputId": "769e3587-6980-415a-931c-31535c8ddb25"
      },
      "source": [
        "nltk.download(['punkt', 'stopwords'])\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAr4WaLVDL2x",
        "outputId": "0d0eeba2-dfdd-41fe-f538-680fd3c0a74f"
      },
      "source": [
        "get_parts(\"weather in tel-aviv\")\n",
        "get_parts(\"weather in TelAviv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FAILED: org [weather in tel-aviv], {'date': 'current'}\n",
            "FAILED: org [weather in TelAviv], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6T_HYP7seLq"
      },
      "source": [
        "## Google search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ry8ASR8NEdKi",
        "outputId": "9b4c81c3-ac08-429f-b7c6-142019e9ed9c"
      },
      "source": [
        "import bs4\n",
        "def get_google(text):\n",
        "  url = \"https://google.com/search?q=\" + text + '&hl=en'\n",
        "  request_result = requests.get( url )\n",
        "  soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
        "  spans = soup.find_all('span', class_='BNeawe')\n",
        "  new_text = ''\n",
        "  for span in spans: \n",
        "    if isinstance(span.contents[0], bs4.NavigableString):\n",
        "      new_text += str(span.contents[0]) + ' '\n",
        "  return new_text\n",
        "get_google(\"weather ra anana\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Ra'anana, Israel  /  Weather \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2lBe7UTUhfO"
      },
      "source": [
        "> when similarity was .075 it matched the sentence\n",
        "\n",
        ">\"tell me how is the weather in the ra- anana in the\"\n",
        "\n",
        ">to \"what's up\" of tag [\"greeting\"] so we increased it to 0.85"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry23BUN9weHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d362a1-dd09-4ab1-a405-875af4604068"
      },
      "source": [
        "do = True\n",
        "GREETING, NOANSWER = 0, 3\n",
        "p(intents['intents'][GREETING]['responses'][0])\n",
        "min_similarity = 0.84\n",
        "VERBOSE = 0\n",
        "\n",
        "while do:\n",
        "  user_msg = input().lower().strip()\n",
        "  if user_msg == '':\n",
        "    answers = intents['intents'][NOANSWER]['responses']\n",
        "    p(\"WeatherBot: \" + random.choice(answers))\n",
        "    continue\n",
        "  round = 0\n",
        "  answer = ''\n",
        "  org_msg = user_msg\n",
        "  while round < 3 and do:\n",
        "    if VERBOSE:   p(f'round {round}: {user_msg}')\n",
        "    doc1 = nlp(user_msg)\n",
        "    answers, tag = None, None\n",
        "    top_similarity = 0\n",
        "    # verify not an erroeous finding (if we have GPE in the doc we assume it is not a general request)\n",
        "    if len([ent for ent in doc1.ents if ent.label_ == 'GPE']) == 0:\n",
        "      for ints in intents['intents']:\n",
        "        #p(ints)\n",
        "        for text in ints['patterns']:\n",
        "          doc2 = nlp(text)\n",
        "          # Get the similarity of doc1 and doc2\n",
        "          similarity = doc1.similarity(doc2)\n",
        "          if VERBOSE > 2: p(f\"{similarity}, {doc2}, {[ints['tag']]}\")\n",
        "          if similarity > top_similarity:\n",
        "            top_similarity = similarity\n",
        "            answers = ints['responses']\n",
        "            tag = ints['tag']\n",
        "    #  p(top_similarity, tag)\n",
        "    #  p(answers)\n",
        "      if top_similarity > min_similarity:\n",
        "        if tag == \"goodbye\":\n",
        "          do = False\n",
        "        if tag in [\"goodbye\", \"greeting\", \"thanks\", \"options\"]:\n",
        "          answer = random.choice(answers)\n",
        "          break\n",
        "    parts = get_parts(user_msg, VERBOSE > 1, False)\n",
        "    if VERBOSE:  p(parts)\n",
        "    if 'date' in parts and 'city' in parts and 'ERROR' not in parts['city'][0][1]:\n",
        "      #p(parts['city'][0][0])\n",
        "      answer = get_weather(parts['date'], parts['city'], action=None)\n",
        "    elif 'city' in parts and 'ERROR' in parts['city'][0][1]:\n",
        "      answer = parts['city'][0][1]\n",
        "    elif round == 0:\n",
        "      round = 1\n",
        "      user_msg = ''\n",
        "      space = ' '\n",
        "      for token in doc1:\n",
        "        if token.text in stopwords: continue\n",
        "        text = token.text.lower().translate(remove_punct_dict)\n",
        "        if text == '': continue\n",
        "        if text[-1] == '-': # take care of 'ra- anana'\n",
        "          user_msg += space + text[:-1]\n",
        "          space = ''\n",
        "        else:\n",
        "          user_msg += space + text\n",
        "          space = ' '\n",
        "      continue\n",
        "    elif round == 1:\n",
        "      round = 2\n",
        "      user_msg = get_google(org_msg)\n",
        "      if user_msg != '':\n",
        "        continue\n",
        "    break\n",
        "  if answer == '': answer = \"You need to tell me a city to check (maybe spell in differently)\"\n",
        "  p(f\"WeatherBot: {answer}\")\n",
        "# weather in jenin, israel  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi. My name is WeatherBot and I'm a chatbot. If you want to exit, type 'Bye' If you want help type 'Help'\n",
            "{'date': 'current', 'city': [('england', 'united states')]}\n",
            "WeatherBot: In England, United states the current weather is: broken clouds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}